{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc7832a8-701a-4164-88f7-087f70e1e280",
   "metadata": {},
   "source": [
    "# Ejercicio 1: Consumo de la API de OpenWeatherMap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64437b90-0431-416a-889c-7a4eb2f92284",
   "metadata": {},
   "source": [
    "## Instalo libreria requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af9806d8-bdc6-4729-82fa-8385a45f20b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\environment-ml\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\environment-ml\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\environment-ml\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\environment-ml\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\environment-ml\\lib\\site-packages (from requests) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406b6c8a-8695-4bed-8873-8042d5ad6a3a",
   "metadata": {},
   "source": [
    "## Descripción de la API\n",
    "La API de OpenWeatherMap permite obtener información meteorológica en tiempo real de cualquier ciudad del mundo. En este ejercicio, utilizo la API para extraer datos del clima actual de Barcelona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a5e3edf-52eb-465f-92ff-f390e649908c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Temperature (°C)</th>\n",
       "      <th>Feels Like (°C)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Pressure (hPa)</th>\n",
       "      <th>Weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barcelona</td>\n",
       "      <td>18.02</td>\n",
       "      <td>17.97</td>\n",
       "      <td>80</td>\n",
       "      <td>1024</td>\n",
       "      <td>broken clouds</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        City  Temperature (°C)  Feels Like (°C)  Humidity (%)  Pressure (hPa)  \\\n",
       "0  Barcelona             18.02            17.97            80            1024   \n",
       "\n",
       "         Weather  \n",
       "0  broken clouds  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importo la libreria requests para obtener la información meteorológica y pandas para generar un dataframe y visualizar la información en formato tabla\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Defino la API Key de OpenWeatherMap\n",
    "api_key = '49dc57f8ca63c0b52177eadc84448cc9'  # denifo la api_key con la clave de API personal obtenida en la api despues de registrarme\n",
    "\n",
    "# Defino la ciudad y la URL de la API\n",
    "city = 'Barcelona'\n",
    "url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}&units=metric\"\n",
    "\n",
    "#Realizo la solicitud a la API\n",
    "response = requests.get(url) # Solicitud a la API\n",
    "data = response.json() #El resultado lo convierto a JSON con data = response.json()\n",
    "\n",
    "# Verifico si la solicitud fue exitosa\n",
    "if response.status_code == 200:\n",
    "    # Extraigo datos específicos de la respuesta JSON\n",
    "    weather_data = {\n",
    "        'City': data['name'],\n",
    "        'Temperature (°C)': data['main']['temp'],\n",
    "        'Feels Like (°C)': data['main']['feels_like'],\n",
    "        'Humidity (%)': data['main']['humidity'],\n",
    "        'Pressure (hPa)': data['main']['pressure'],\n",
    "        'Weather': data['weather'][0]['description']\n",
    "    }\n",
    "    \n",
    "    # Convierto los datos a un DataFrame para mejorar la presentación\n",
    "    df_weather = pd.DataFrame([weather_data])\n",
    "    display(df_weather)  # Uso display para visualizar en Jupyter Notebook\n",
    "\n",
    "else:\n",
    "    print(\"Error en la solicitud:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d92e1eb-a911-466e-8f25-4e70c63d0147",
   "metadata": {},
   "source": [
    "# Ejercicio 2: Obtener datos con Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6200bb-bc2a-49fa-8cf5-f5abe0aa05dd",
   "metadata": {},
   "source": [
    "## Instalo libreria beutifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b8380dc-bc54-4df0-b7bb-6c5132ed6d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\environment-ml\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\anaconda3\\envs\\environment-ml\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\environment-ml\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\environment-ml\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\environment-ml\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\environment-ml\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\anaconda3\\envs\\environment-ml\\lib\\site-packages (from beautifulsoup4) (2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5a562d-87d7-45b0-9b7f-002277ebc8ed",
   "metadata": {},
   "source": [
    "## Código para realizar web scraping: Obtengo citas y autores de quotes.toscrape.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1988e37-6d2b-4866-81e2-d2f7e543803c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quote</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“The world as we have created it is a process ...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“It is our choices, Harry, that show what we t...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“There are only two ways to live your life. On...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“The person, be it gentleman or lady, who has ...</td>\n",
       "      <td>Jane Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“Imperfection is beauty, madness is genius and...</td>\n",
       "      <td>Marilyn Monroe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               quote           author\n",
       "0  “The world as we have created it is a process ...  Albert Einstein\n",
       "1  “It is our choices, Harry, that show what we t...     J.K. Rowling\n",
       "2  “There are only two ways to live your life. On...  Albert Einstein\n",
       "3  “The person, be it gentleman or lady, who has ...      Jane Austen\n",
       "4  “Imperfection is beauty, madness is genius and...   Marilyn Monroe"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL de la página a scrapear\n",
    "url = \"http://quotes.toscrape.com/\"\n",
    "\n",
    "# Realizo la solicitud a la página\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Extraigo las citas y los autores\n",
    "quotes = []\n",
    "authors = []\n",
    "\n",
    "for quote in soup.find_all('div', class_='quote'):\n",
    "    quotes.append(quote.find('span', class_='text').get_text())\n",
    "    authors.append(quote.find('small', class_='author').get_text())\n",
    "\n",
    "# Transformo los datos a un DataFrame\n",
    "df_quotes = pd.DataFrame({\n",
    "    'quote': quotes,\n",
    "    'author': authors\n",
    "})\n",
    "\n",
    "# Visualizo los datos\n",
    "df_quotes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2814b0-14b3-4338-a5ce-d14690246902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
